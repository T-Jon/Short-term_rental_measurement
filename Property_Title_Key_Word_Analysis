# Key word analysis looking at key words, including bi-grams or key word pairs, for market analysis and key word optimization.
# This script will produce both bar charts and word maps using single key words and key word pairs using the property titles as found in the wild for STR property descriptions.

import pandas as pd
from pandasql import sqldf
import os
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import nltk
from collections import Counter
from nltk import bigrams as nltk_bigrams
import matplotlib.pyplot as plt
from wordcloud import WordCloud


nltk.download('punkt')
nltk.download('stopwords')

# Define a helper function for SQL queries
pysqldf = lambda q: sqldf(q, globals())


def extract_keywords(text_series):
    stop_words = set(stopwords.words('english'))
    # Additional stop words can be added based on domain-specific needs
    additional_stopwords = {'&', 'with', '-', '|'}
    stop_words.update(additional_stopwords)
    
    all_words = []
    all_bigrams = []  # Initialize all_bigrams list here to collect bigrams from all titles

    for title in text_series:
        words = word_tokenize(title.lower())  # Tokenize and convert to lower case
        keywords = [word for word in words if word.isalpha() and word not in stop_words]
        all_words.extend(keywords)

        bigram_keywords = list(nltk_bigrams(keywords))  # Generate bigrams from filtered keywords
        all_bigrams.extend(bigram_keywords)
    
    return Counter(all_words), Counter(all_bigrams)


def generate_wordcloud(counter, title):
    if title == 'Word Cloud for Top Bigrams':
        counter = {f'{word[0]} {word[1]}': count for word, count in counter.items()}
        
    wordcloud = WordCloud(width = 800, height = 800, 
                          background_color ='black', 
                          min_font_size = 10).generate_from_frequencies(counter)

    plt.figure(figsize = (8, 8), facecolor = None) 
    plt.imshow(wordcloud) 
    plt.axis("off") 
    plt.title(title)
    plt.tight_layout(pad = 0) 
    plt.show()


def plot_most_common(counter, title, n=20):
    # Extract the most common words/bigrams and their counts
    most_common = counter.most_common(n)
    words = [item[0] for item in most_common]
    counts = [item[1] for item in most_common]

    plt.figure(figsize=(10, 8))
    plt.barh(range(len(words)), counts, color='skyblue')
    plt.yticks(range(len(words)), words)
    plt.gca().invert_yaxis()  # Invert the y-axis to have the highest count at the top
    plt.xlabel('Frequency')
    plt.title(title)
    plt.show()

# Directory where CSV files are stored
data_dir = r'C:\Users\Ty\Desktop\Expedia_Analysis\data'

# List of specific CSV files to process
specific_csv_files = [
    'data_2024_April_300.csv',
    'data_2024_May_300.csv'
]

all_keywords = Counter()
all_bigrams = Counter()

for filename in specific_csv_files:
    file_path = os.path.join(data_dir, filename)
    df = pd.read_csv(file_path)
    
    if 'Property Title' in df.columns:
        keywords_counter, bigrams_counter = extract_keywords(df['Property Title'])
        all_keywords += keywords_counter
        all_bigrams += bigrams_counter 

# Display the most common keywords
print("Top single keywords:")
print(all_keywords.most_common(20))
print("\nTop bigrams:")
print(all_bigrams.most_common(20))
plot_most_common(all_keywords, 'Top 20 Keywords')
plot_most_common(all_bigrams, 'Top 20 Bigrams', n=10)
generate_wordcloud(all_keywords, 'Word Cloud for Top Keywords')
generate_wordcloud(all_bigrams, 'Word Cloud for Top Bigrams')
